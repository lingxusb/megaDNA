{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e1569-f972-4e78-9139-d4671b59b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from MEGABYTE_pytorch import MEGABYTE\n",
    "\n",
    "nucleotides = ['**', 'A', 'T', 'C', 'G', '#'] # vocabulary\n",
    "PRIME_LENGTH = 4 # give the model a random DNA primer to start\n",
    "num_seq = 200 # number of runs\n",
    "context_length = 50000 # maximal length for the generated sequence, depend on your GPU memory\n",
    "model_path = \"megaDNA_phage_145M.pt\" # model name\n",
    "\n",
    "for j in range(1, num_seq):\n",
    "    # Load the pre-trained model\n",
    "    model = torch.load(model_path)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # set the random DNA primer\n",
    "    primer_sequence = torch.tensor([[random.choice(np.arange(1,5)) for _ in range(PRIME_LENGTH)]]).long().cuda()\n",
    "    primer_DNA = ''.join(nucleotides[_] for _ in primer_sequence[0])\n",
    "    print(f\"Primer sequence: {primer_DNA}\\n{'*' * 100}\")\n",
    "\n",
    "    # Generate a sequence using the model\n",
    "    generated_sequence = model.generate(primer_sequence, \n",
    "                                        seq_len=context_length, \n",
    "                                        temperature=0.95, \n",
    "                                        filter_thres=0.0)\n",
    "    generated_str = ''.join([nucleotides[int(s)] for s in generated_sequence[0].flatten(0).cpu()])\n",
    "\n",
    "    # Split the generated sequence into contigs at the '#' character\n",
    "    contigs = generated_str.split('#')\n",
    "\n",
    "    # Write the contigs to a .fna file\n",
    "    output_file_path = f\"generate_{j}.fna\"\n",
    "    with open(output_file_path, \"w\") as file:\n",
    "        for idx, contig in enumerate(contigs):\n",
    "            if len(contig) > 0:\n",
    "                file.write(f\">contig_{idx}\\n{contig}\\n\")\n",
    "    \n",
    "    # Clean up to free memory\n",
    "    del model, primer_sequence, generated_str\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5517d-cbf9-41f1-a971-f2d57fadd5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
