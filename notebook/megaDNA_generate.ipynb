{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b9c3d-99e8-4a08-8a2c-6ce8464b56d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleotides = ['**', 'A', 'T', 'C', 'G', '#'] # vocabulary\n",
    "def token2nucleotide(s):\n",
    "    return nucleotides[s]\n",
    "\n",
    "PRIME_LENGTH = 4 # give the model a random DNA primer to start\n",
    "num_seq = 2 # number of runs\n",
    "context_length = 10000 # maximal length for the generated sequence, depend on your GPU memory (upper limit is 131K)\n",
    "\n",
    "# model can be downloaded from https://huggingface.co/lingxusb/megaDNA_updated/resolve/main/megaDNA_phage_145M.pt\n",
    "model_path = \"megaDNA_phage_145M.pt\" # model name\n",
    "device = 'cpu' # change this to 'cuda' if you use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbe45ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(num_seq):\n",
    "    # Load the pre-trained model\n",
    "    model = torch.load(model_path, map_location=torch.device(device))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # set the random DNA primer\n",
    "    primer_sequence = torch.tensor(np.random.choice(np.arange(1,5), PRIME_LENGTH)).long().to(device)[None,]\n",
    "    primer_DNA = ''.join(map(token2nucleotide, primer_sequence[0]))\n",
    "    print(f\"Primer sequence: {primer_DNA}\\n{'*' * 100}\")\n",
    "\n",
    "    # Generate a sequence using the model\n",
    "    seq_tokenized = model.generate(primer_sequence, \n",
    "                                   seq_len=context_length,\n",
    "                                   temperature=0.95, \n",
    "                                   filter_thres=0.0)\n",
    "    generated_sequence = ''.join(map(token2nucleotide, seq_tokenized.squeeze().cpu().int()))\n",
    "\n",
    "    # Split the generated sequence into contigs at the '#' character\n",
    "    contigs = generated_sequence.split('#')\n",
    "\n",
    "    # Write the contigs to a .fna file\n",
    "    output_file_path = f\"generate_{1+j}.fna\"\n",
    "    with open(output_file_path, \"w\") as file:\n",
    "        for idx, contig in enumerate(contigs):\n",
    "            if len(contig) > 0:\n",
    "                file.write(f\">contig_{idx}\\n{contig}\\n\")\n",
    "    \n",
    "    # Clean up to free memory\n",
    "    del model, primer_sequence, generated_sequence\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8455ed2b-8c43-4ea3-99c0-6b94fa52c97a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
